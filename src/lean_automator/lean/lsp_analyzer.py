# src/lean_automator/lean/lsp_analyzer.py

"""Provides detailed analysis of Lean code failures using the Lean LSP server.

This module utilizes the Lean Language Server Protocol (LSP) client to diagnose
errors in Lean code snippets, typically those generated by an LLM that failed
verification.

The primary function, `analyze_lean_failure`, orchestrates the interaction
with the LSP server via the `LeanLspClient`:
1. Pre-processes the input Lean code.
2. Optionally runs a quick `lean` command check for early errors.
3. Starts the `LeanLspClient` connected to `lean --server`.
4. Sends the code to the server (`textDocument/didOpen`).
5. Collects diagnostics (errors, warnings) reported by the server.
6. Queries the proof goal state (`$/lean/plainGoal`) before relevant lines,
   marking goals as 'N/A' after the first detected error line.
7. Assembles an annotated version of the processed code, interleaving
   goal states and diagnostics as comments.
8. Appends any original high-level build error messages.

The resulting annotated code provides detailed, contextual feedback suitable
for guiding an LLM in self-correction attempts.
"""

import asyncio
import logging
import os
import pathlib
import re
import subprocess
from collections import defaultdict
from typing import Any, Dict, List, Optional, Tuple

# Import the LSP client and specific error from the new module
from .lsp_client import LeanLspClient, LspResponseError

# --- Logging Configuration ---
# Configure logging level using the LOGLEVEL environment variable.
# Basic configuration should be set globally.
logging.basicConfig(
    level=os.environ.get("LOGLEVEL", "INFO").upper(),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# Default timeout for analysis steps, can be overridden in analyze_lean_failure
DEFAULT_ANALYSIS_TIMEOUT = 60 # Increased default for the whole analysis function


# --- Module-Level Helper Functions ---

def strip_lean_comments(lean_code: str) -> str:
    """Strips single-line Lean comments (--...) from code.

    Args:
        lean_code: The Lean code string.

    Returns:
        The Lean code with single-line comments removed.
    """
    lines = lean_code.splitlines()
    # Remove comments, but keep line structure (even if line becomes empty)
    stripped_lines = [re.sub(r"--.*$", "", line) for line in lines]
    return "\n".join(stripped_lines)


def _get_lean_path_env(
    exec_path: str, project_cwd: str, lib_path: Optional[pathlib.Path]
) -> Dict[str, str]:
    """Constructs the environment dictionary with LEAN_PATH set.

    Used for running standalone `lean` commands, attempts to mirror the
    paths the LSP client would use (stdlib, shared lib, project build).

    Args:
        exec_path: Path to the 'lean' executable.
        project_cwd: Working directory for the lean process (temp project).
        lib_path: Optional path to the root of the shared library dependency.

    Returns:
        A dictionary representing the environment variables with LEAN_PATH
        configured.
    """
    subprocess_env = os.environ.copy()
    lean_paths: List[str] = []
    seen_paths = set() # To avoid duplicates based on resolved paths

    # 1. Detect Stdlib Path (synchronous call)
    try:
        lean_path_proc = subprocess.run(
            [exec_path, "--print-libdir"],
            capture_output=True,
            text=True,
            check=True,
            timeout=10,
            encoding="utf-8",
        )
        path_candidate = lean_path_proc.stdout.strip()
        if path_candidate and pathlib.Path(path_candidate).is_dir():
            std_lib_path = path_candidate
            resolved_p = str(pathlib.Path(std_lib_path).resolve())
            if resolved_p not in seen_paths:
                logger.debug(f"Path Env (Helper): Detected Lean stdlib path: {std_lib_path}")
                lean_paths.append(std_lib_path)
                seen_paths.add(resolved_p)
        else:
            logger.warning(f"Path Env (Helper): --print-libdir invalid output: '{path_candidate}'")
    except Exception as e:
        logger.warning(f"Path Env (Helper): Failed to detect Lean stdlib path: {e}")

    # 2. Add Shared Library Build Path
    if lib_path and lib_path.is_dir():
        shared_lib_build_path = lib_path / ".lake" / "build" / "lib"
        if shared_lib_build_path.is_dir():
            abs_path = str(shared_lib_build_path.resolve())
            if abs_path not in seen_paths:
                logger.debug(f"Path Env (Helper): Adding shared lib build path: {abs_path}")
                lean_paths.append(str(shared_lib_build_path)) # Use original form
                seen_paths.add(abs_path)
        else:
            logger.warning(f"Path Env (Helper): Shared lib path provided but build dir not found: {shared_lib_build_path}")
    elif lib_path:
        logger.warning(f"Path Env (Helper): Provided shared_lib_path is not a valid directory: {lib_path}")

    # 3. Add Temporary Project's *Own* Build Path
    temp_project_build_path = pathlib.Path(project_cwd) / ".lake" / "build" / "lib"
    abs_temp_path = str(temp_project_build_path.resolve())
    if abs_temp_path not in seen_paths:
        logger.debug(f"Path Env (Helper): Adding temp project's own build path: {abs_temp_path}")
        lean_paths.append(str(temp_project_build_path)) # Add even if it doesn't exist yet
        seen_paths.add(abs_temp_path)

    # 4. Combine with existing LEAN_PATH
    existing_lean_path = subprocess_env.get("LEAN_PATH")
    if existing_lean_path:
        # Add components of existing path individually to check uniqueness
        for p in existing_lean_path.split(os.pathsep):
             if p: # Ignore empty components
                resolved_p = str(pathlib.Path(p).resolve())
                if resolved_p not in seen_paths:
                    logger.debug(f"Path Env (Helper): Adding existing LEAN_PATH component: {p}")
                    lean_paths.append(p)
                    seen_paths.add(resolved_p)

    # Set the final LEAN_PATH
    if lean_paths:
        final_lean_path = os.pathsep.join(lean_paths)
        subprocess_env["LEAN_PATH"] = final_lean_path
        logger.info(f"Path Env (Helper): Setting LEAN_PATH: {final_lean_path}")
    else:
        logger.warning("Path Env (Helper): Could not determine any paths for LEAN_PATH.")

    return subprocess_env


def _preprocess_lean_code(lean_code: str) -> str:
    """Preprocesses Lean code by stripping comments and cleaning blank lines.

    Removes single-line Lean comments (`--...`). It then removes any line
    that consists *only* of whitespace after its comment was removed.
    Original blank lines or lines with content after comment stripping are kept.

    Args:
        lean_code: The raw Lean code string.

    Returns:
        The processed Lean code string.
    """
    original_lines = lean_code.splitlines()
    processed_lines = []
    comment_pattern = re.compile(r"--.*$")
    comment_search_pattern = re.compile(r"--")

    for original_line in original_lines:
        had_comment = comment_search_pattern.search(original_line) is not None
        stripped_line = comment_pattern.sub("", original_line)
        is_blank_after_strip = not stripped_line.strip()

        # Discard line ONLY if it had a comment AND became blank after stripping.
        if had_comment and is_blank_after_strip:
            continue
        else:
            processed_lines.append(stripped_line)

    return "\n".join(processed_lines)


def _parse_goal_result(goal_result: Optional[Any]) -> str:
    """Parses the LSP goal result structure into a display string.

    Handles various potential formats returned by `$/lean/plainGoal`.

    Args:
        goal_result: The raw result object returned by the LSP client's
            `get_goal` method, or None if the request failed.

    Returns:
        A string representation of the goal state, or an indicator
        if no goal state was reported or an error occurred upstream.
    """
    if goal_result is None:
        # This case occurs if client.get_goal returned None (e.g., timeout, error)
        # The caller (_analyze_lean_failure_internal) handles logging specific errors.
        return "Error: Failed to retrieve goal state"

    if isinstance(goal_result, dict):
        # Prioritize 'rendered' if available (often formatted nicely)
        if "rendered" in goal_result:
            return goal_result["rendered"].strip()
        if "plainGoal" in goal_result: # Fallback to plainGoal
            return goal_result["plainGoal"].strip()
        # Handle case where 'goals' list might be present (less common for plainGoal?)
        if ("goals" in goal_result and
            isinstance(goal_result["goals"], list) and
            goal_result["goals"]):
                return f"{len(goal_result['goals'])} goal(s): " + " | ".join(
                    [g.get("rendered", str(g)).replace("\n", " ") for g in goal_result["goals"]]
                )
        # If known fields aren't found, represent the dict structure partially
        return f"Goal state (unknown format): {str(goal_result)[:300]}"
    elif isinstance(goal_result, str): # If the result was just a string
        return goal_result.strip()
    else: # Handle unexpected types
        return f"Unexpected goal result type: {type(goal_result).__name__} ({str(goal_result)[:100]})"


def _clean_goal_string(goal_str: str) -> Tuple[str, str]:
    """Cleans a goal string and creates a compact single-line version.

    Removes markdown code fences, trims whitespace, handles empty/no goal
    states, and replaces newlines with semicolons for the single-line format.

    Args:
        goal_str: The goal string, potentially multi-line and with formatting.

    Returns:
        A tuple containing:
            - cleaned (str): The cleaned, potentially multi-line goal string.
            - single_line (str): A compact, single-line version of the goal.
    """
    cleaned = goal_str.strip()
    if cleaned.startswith("```lean"):
        cleaned = cleaned.removeprefix("```lean").strip()
    if cleaned.endswith("```"):
        cleaned = cleaned.removesuffix("```").strip()

    if not cleaned or "no goals" in cleaned.lower():
        cleaned = "goals accomplished" # Standardize empty/accomplished state

    # Create single-line version, replacing newlines
    single_line = cleaned.replace("\n", "; ").strip()
    # Further condense multiple spaces that might result from replacements
    single_line = re.sub(r'\s{2,}', ' ', single_line)

    return cleaned, single_line


def _format_diagnostic_line(diag: Dict[str, Any], line_idx: int) -> str:
    """Formats a single LSP diagnostic into a comment line for annotation.

    Args:
        diag: The diagnostic object from the LSP server.
        line_idx: The 0-based index of the line in the *processed* code
                  to which this diagnostic primarily pertains (used for display).

    Returns:
        A formatted string intended to be inserted as a comment line
        before the corresponding code line.
    """
    severity_map = {1: "Error", 2: "Warning", 3: "Info", 4: "Hint"}
    severity = severity_map.get(diag.get("severity", 0), "Diagnostic") # Default if unknown
    message = diag.get("message", "Unknown diagnostic message.")
    diag_range = diag.get("range", {})
    start_pos = diag_range.get("start", {})
    end_pos = diag_range.get("end", {})

    # Display positions are 1-based for user readability
    start_line_disp = start_pos.get("line", -1) + 1
    start_char_disp = start_pos.get("character", -1) + 1
    end_line_disp = end_pos.get("line", -1) + 1
    end_char_disp = end_pos.get("character", -1) + 1

    # Format the diagnostic comment line, adding indentation for clarity
    return (
        f"  -- {severity}: (Reported range L{start_line_disp}:{start_char_disp}"
        f"-L{end_line_disp}:{end_char_disp}): {message}"
    )


# --- Main Analysis Function ---

async def analyze_lean_failure(
    lean_code: str,
    lean_executable_path: str,
    cwd: str,
    shared_lib_path: Optional[pathlib.Path],
    timeout_seconds: int = DEFAULT_ANALYSIS_TIMEOUT,
    fallback_error: str = "Build system analysis failed.",
) -> str:
    """
    Analyzes failing Lean code using LSP for detailed diagnostics and goal states.

    Orchestrates the process of preprocessing code, running an optional pre-check,
    interacting with the Lean LSP server via LeanLspClient, collecting diagnostics
    and goal states, and assembling an annotated code report.

    Args:
        lean_code: The Lean code string to analyze.
        lean_executable_path: Path to the 'lean' executable.
        cwd: Working directory for the lean server process (temp project).
        shared_lib_path: Path to the root of the shared library dependency, used
            for setting LEAN_PATH for both pre-check and the LSP server.
        timeout_seconds: Timeout for the entire analysis process, including
                         subprocess calls and individual LSP requests within the client.
        fallback_error: Original error message (e.g., from `lake build`) to append
                       to the analysis output.

    Returns:
        Annotated Lean code string with goal states (or 'N/A' after first error),
        LSP diagnostics as comments, and the appended build error message.
    """

    # --- Pre-check using direct lean execution ---
    first_compiler_error_line = float("inf") # Use 1-based indexing from compiler
    temp_precheck_filename = "precheck_analysis_file.lean"
    temp_precheck_path = pathlib.Path(cwd) / temp_precheck_filename

    logger.debug("Preprocessing Lean code for analysis...")
    processed_code = _preprocess_lean_code(lean_code)

    try:
        logger.info(f"Pre-check: Writing processed code to {temp_precheck_path}")
        temp_precheck_path.write_text(processed_code, encoding="utf-8")

        logger.info(f"Pre-check: Running: {lean_executable_path} {temp_precheck_filename}")
        # Use a fraction of the total timeout for the pre-check
        precheck_timeout = max(5, timeout_seconds // 3)
        precheck_env = _get_lean_path_env(lean_executable_path, cwd, shared_lib_path)

        result = await asyncio.to_thread( # Run blocking subprocess in thread
            subprocess.run,
            [lean_executable_path, temp_precheck_filename],
            capture_output=True,
            text=True,
            cwd=cwd,
            timeout=precheck_timeout,
            encoding="utf-8",
            errors="replace",
            env=precheck_env,
            check=False # Don't raise exception on non-zero exit code
        )

        # Parse stdout/stderr for the first error line
        error_pattern = re.compile(r".*?:(\d+):\d+:\s*error:")
        output_to_scan = result.stdout + "\n" + result.stderr # Combine outputs
        output_lines = output_to_scan.splitlines()
        logger.debug(f"Pre-check stdout/stderr ({len(output_lines)} lines): {output_to_scan[:500]}...")

        for line_num_str in (match.group(1) for match in (error_pattern.match(line) for line in output_lines) if match):
            try:
                # Line number refers to lines in the processed code file
                first_compiler_error_line = int(line_num_str)
                logger.info(f"Pre-check: Found first compiler error on line: {first_compiler_error_line} (in processed code)")
                break # Stop after finding the first one
            except ValueError:
                logger.warning(f"Pre-check: Failed to parse line number from match: {line_num_str}")

        if first_compiler_error_line == float("inf"):
            logger.info("Pre-check: No errors found matching pattern in compiler output.")

    except FileNotFoundError:
        logger.error(f"Pre-check Failed: Lean executable not found at '{lean_executable_path}'.")
    except subprocess.TimeoutExpired:
        logger.warning(f"Pre-check: Timed out after {precheck_timeout}s.")
    except Exception as precheck_e:
        logger.warning(f"Pre-check: Failed with unexpected error: {precheck_e}", exc_info=True)
    finally:
        # Clean up the temporary file
        if temp_precheck_path.exists():
            try:
                temp_precheck_path.unlink()
                logger.debug(f"Pre-check: Cleaned up {temp_precheck_path}")
            except OSError as e:
                logger.warning(f"Pre-check: Could not delete temp file {temp_precheck_path}: {e}")

    # --- Initialize LSP Client ---
    # Use a reasonable timeout for individual client operations, less than total
    client_timeout = max(15, timeout_seconds // 2)
    client = LeanLspClient(
        lean_executable_path,
        cwd,
        timeout=client_timeout,
        shared_lib_path=shared_lib_path,
    )

    # --- Analysis Variables ---
    analysis_succeeded = False
    collected_diagnostics: List[Dict[str, Any]] = []
    diagnostics_by_line: Dict[int, List[str]] = defaultdict(list)
    first_lsp_error_line_idx = float("inf")  # Use 0-based indexing for LSP
    effective_error_line_idx = float("inf")  # 0-based index combining pre-check & LSP

    # --- File URI ---
    temp_filename = "temp_analysis_file.lean"
    temp_file_path = pathlib.Path(cwd) / temp_filename
    temp_file_uri = temp_file_path.as_uri()

    # Wrap core LSP interaction in try/finally to ensure client close
    final_output_lines: List[str] = []
    try:
        # --- Start LSP and Open Document ---
        logger.info("Starting LSP client...")
        await client.start_server()
        await client.initialize() # Handshake

        # Base the analysis on the lines from the processed code
        code_lines = processed_code.splitlines()

        # Send the processed code content to the LSP server
        await client.did_open(temp_file_uri, "lean", 1, processed_code)
        logger.info(f"Sent textDocument/didOpen for URI {temp_file_uri}")

        # --- Wait for initial diagnostics ---
        # Give Lean LSP time to process the file after opening.
        initial_wait_time = min(10.0, client_timeout / 2) # Wait up to 10s
        logger.info(f"Waiting {initial_wait_time:.1f}s for initial diagnostics...")
        await asyncio.sleep(initial_wait_time)
        # Collect diagnostics generated so far
        initial_diagnostics = await client.get_diagnostics(timeout=1.0)
        collected_diagnostics.extend(initial_diagnostics)
        logger.info(f"Collected {len(initial_diagnostics)} initial diagnostics.")

        # --- Determine effective error line ---
        # Find first error line from collected LSP diagnostics
        for diag in collected_diagnostics:
            if diag.get("severity") == 1:  # 1 is Error severity in LSP
                try:
                    line_idx = diag.get("range", {}).get("start", {}).get("line", float("inf"))
                    first_lsp_error_line_idx = min(first_lsp_error_line_idx, float(line_idx))
                except (ValueError, TypeError):
                    logger.warning(f"Could not parse line number from diagnostic: {diag}")

        # Combine pre-check (1-based) and LSP error (0-based) into 0-based index
        effective_error_line_idx = min(
            float(first_compiler_error_line) - 1, # Convert pre-check line to 0-based
            first_lsp_error_line_idx
        )

        if effective_error_line_idx != float("inf"):
            effective_error_line_idx = int(effective_error_line_idx) # Convert back to int if found
            logger.info(f"Effective first error detected near line index: {effective_error_line_idx} (Line {effective_error_line_idx + 1} in processed code)")
        else:
            logger.info("No errors detected from pre-check or initial LSP diagnostics.")
            effective_error_line_idx = -1 # Use -1 to indicate no error found

        # --- Goal fetching loop ---
        logger.info("Starting line-by-line goal annotation (marking N/A after error)...")
        goal_lines_buffer: List[Optional[str]] = [] # Store goals or None/Error/NA
        code_lines_buffer: List[str] = code_lines # Use processed code lines

        for i, line_content in enumerate(code_lines_buffer):
            goal_comment_line: Optional[str] = None # Default to no goal comment

            # Only fetch goals for non-empty/non-whitespace lines
            if line_content.strip():
                if effective_error_line_idx != -1 and i >= effective_error_line_idx:
                    # Error detected earlier, mark goal as N/A
                    goal_comment_line = f"-- Goal: N/A (error detected near line {effective_error_line_idx + 1})"
                    logger.debug(f"Marking goal N/A for code line index {i}")
                else:
                    # No error detected yet *at or before* this line, try to fetch goal
                    goal_status_msg = "Error: Default goal retrieval failure" # Placeholder
                    try:
                        # Use client's timeout setting for individual goal request
                        goal_result = await client.get_goal(temp_file_uri, line=i, character=0)

                        # goal_result can be None if client.get_goal had an error/timeout
                        parsed_goal = _parse_goal_result(goal_result) # Handles None case internally
                        if parsed_goal.startswith("Error:"):
                            goal_status_msg = parsed_goal # Use error from parsing
                            logger.warning(f"Failed to parse goal result for line {i+1}: {parsed_goal}")
                        else:
                            _, single_line_goal = _clean_goal_string(parsed_goal)
                            goal_comment_line = f"-- Goal: {single_line_goal}"
                            goal_status_msg = "Success" # Mark as success

                    # client.get_goal handles internal LspResponseError, TimeoutError, etc.
                    # and returns None in those cases. _parse_goal_result turns None into an error string.
                    # We catch broader errors here that might occur outside the client call itself.
                    except ConnectionError as goal_conn_e:
                         logger.error(f"Connection error during goal retrieval loop for line {i+1}: {goal_conn_e}")
                         goal_status_msg = "-- Goal: Error: Connection failed during goal retrieval"
                         # Consider breaking the loop if connection is lost
                         # break
                    except Exception as goal_e:
                        logger.error(f"Unexpected error during goal processing for line {i + 1}: {goal_e}", exc_info=True)
                        goal_status_msg = f"-- Goal: Error processing goal: {type(goal_e).__name__}"

                    # If goal fetching resulted in an error message instead of a goal
                    if goal_comment_line is None:
                         goal_comment_line = f"-- Goal: {goal_status_msg}"


            goal_lines_buffer.append(goal_comment_line) # Append goal/N/A/Error/None

        # --- Collect final diagnostics and process ---
        # Fetch diagnostics again in case more arrived during goal fetching.
        diagnostic_collection_timeout = min(5.0, client_timeout)
        logger.info(f"Collecting final diagnostics (timeout={diagnostic_collection_timeout:.1f}s)...")
        more_diagnostics = await client.get_diagnostics(timeout=diagnostic_collection_timeout)
        collected_diagnostics.extend(more_diagnostics)
        logger.info(f"Total collected diagnostics: {len(collected_diagnostics)}")

        # Process all collected diagnostics for inline reporting
        if collected_diagnostics:
            logger.debug(f"Processing {len(collected_diagnostics)} total diagnostics...")
            formatted_diags_count = 0
            seen_diags = set() # De-duplicate based on key fields
            for diag in collected_diagnostics:
                 diag_sig = (
                    diag.get("severity"),
                    diag.get("range", {}).get("start", {}).get("line"),
                    diag.get("range", {}).get("start", {}).get("character"),
                    diag.get("range", {}).get("end", {}).get("line"),
                    diag.get("range", {}).get("end", {}).get("character"),
                    diag.get("message"),
                )
                 if diag_sig in seen_diags:
                    continue
                 seen_diags.add(diag_sig)

                 # Get the primary line index (refers to processed lines)
                 start_line_idx = diag.get("range", {}).get("start", {}).get("line", -1)
                 if start_line_idx != -1 and start_line_idx < len(code_lines_buffer):
                    # Pass the correct line index from the processed code
                    diag_log_line = _format_diagnostic_line(diag, start_line_idx)
                    diagnostics_by_line[start_line_idx].append(diag_log_line)
                    formatted_diags_count += 1
                 else:
                      logger.warning(f"Diagnostic reported for invalid line index {start_line_idx}: {diag}")

            logger.info(f"Processed {formatted_diags_count} unique diagnostics into line map.")

        # --- Assemble final output ---
        logger.info("Assembling final annotated output...")
        # Iterate using the processed code lines buffer
        for i, code_line in enumerate(code_lines_buffer):
            # 1. Add goal comment (if any for this line)
            goal_comment = goal_lines_buffer[i]
            if goal_comment is not None:
                # Exclude noisy "no goal" messages unless they indicate accomplishment
                if (goal_comment != "-- Goal: No goal state reported" or
                    "accomplished" in goal_comment):
                    final_output_lines.append(goal_comment)

            # 2. Add diagnostics reported for this line index *before* the code
            if i in diagnostics_by_line:
                final_output_lines.extend(diagnostics_by_line[i])
                logger.debug(f"Inserted {len(diagnostics_by_line[i])} diagnostics before line index {i}")

            # 3. Add the processed code line
            final_output_lines.append(code_line)

        logger.info("Finished assembling annotated output.")
        analysis_succeeded = True

    except ConnectionError as e:
        logger.error(f"LSP Connection Error during analysis: {e}")
        final_output_lines.append(f"-- Error: LSP Connection Failed: {e}")
        analysis_succeeded = False
    except asyncio.TimeoutError as e:
        # This might catch timeouts during client setup/initialization
        logger.error(f"LSP Overall Timeout Error during analysis: {e}")
        final_output_lines.append(f"-- Error: LSP Timeout during analysis setup: {e}")
        analysis_succeeded = False
    except Exception as e:
        logger.exception(f"Unhandled exception during LSP analysis orchestration: {e}")
        final_output_lines.append(f"-- Error: Unexpected analysis failure: {e}")
        analysis_succeeded = False
    finally:
        # Ensure LSP Client is closed gracefully
        if 'client' in locals() and client:
            logger.info("Shutting down LSP client...")
            await client.close() # Use the client's comprehensive close method

    # --- Append Build Error Section ---
    # Ensure final_output_lines exists even if analysis failed very early
    if not final_output_lines and not analysis_succeeded:
        final_output_lines = ["-- Analysis failed before generating LSP output --"]

    # Add appropriate header based on success/failure
    if not analysis_succeeded and (not final_output_lines or not final_output_lines[0].startswith("-- Error:")):
         final_output_lines.insert(0, "-- LSP Analysis Incomplete --")

    # Append the original fallback error message
    final_output_lines.append("\n-- Build System Output --")
    if fallback_error:
        # Indent fallback error lines for clarity
        fallback_lines = ["--   " + line for line in fallback_error.strip().splitlines()]
        final_output_lines.extend(fallback_lines)
    else:
        final_output_lines.append("-- (Original build system output not provided)")

    # --- Return Final Result ---
    return "\n".join(final_output_lines)